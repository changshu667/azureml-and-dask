{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading your Data from an AzureML Datastore\n",
    "\n",
    "**Important**: Make sure to execute the steps to start the cluster in the notebook [StartDask.ipynb](StartDask.ipynb) before running this noteboook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.74'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core import VERSION\n",
    "import time\n",
    "VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the data to the AzureML Datastore\n",
    "AzureML has the concept of a Datastore that can be mounted to a job, so you script does not have to deal with reading from Azure Blobstorage. First, let's download some data and upload it to the blob store, so we can play with it in Dask\n",
    "(parts of this code originates from https://github.com/dask/dask-tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Uploading flight data... \n",
      "Uploading an estimated of 10 files\n",
      "Target already exists. Skipping upload for nycflights/1990.csv\n",
      "Target already exists. Skipping upload for nycflights/1991.csv\n",
      "Target already exists. Skipping upload for nycflights/1992.csv\n",
      "Target already exists. Skipping upload for nycflights/1993.csv\n",
      "Target already exists. Skipping upload for nycflights/1994.csv\n",
      "Target already exists. Skipping upload for nycflights/1995.csv\n",
      "Target already exists. Skipping upload for nycflights/1996.csv\n",
      "Target already exists. Skipping upload for nycflights/1997.csv\n",
      "Target already exists. Skipping upload for nycflights/1998.csv\n",
      "Target already exists. Skipping upload for nycflights/1999.csv\n",
      "Uploaded 0 files\n",
      "** Finished! **\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "data_dir = os.path.abspath(os.path.join(cwd, 'data'))\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs('data')\n",
    "\n",
    "flights_raw = os.path.join(data_dir, 'nycflights.tar.gz')\n",
    "flightdir = os.path.join(data_dir, 'nycflights')\n",
    "\n",
    "if not os.path.exists(flights_raw):\n",
    "    print(\"- Downloading NYC Flights dataset... \", end='', flush=True)\n",
    "    url = \"https://storage.googleapis.com/dask-tutorial-data/nycflights.tar.gz\"\n",
    "    urllib.request.urlretrieve(url, flights_raw)\n",
    "    print(\"done\", flush=True)\n",
    "\n",
    "if not os.path.exists(flightdir):\n",
    "    print(\"- Extracting flight data... \", end='', flush=True)\n",
    "    tar_path = os.path.join(data_dir, 'nycflights.tar.gz')\n",
    "    with tarfile.open(tar_path, mode='r:gz') as flights:\n",
    "        flights.extractall('data/')\n",
    "    print(\"done\", flush=True)\n",
    "\n",
    "    \n",
    "print(\"- Uploading flight data... \")\n",
    "ws = Workspace.from_config()\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "ds.upload(src_dir=flightdir,\n",
    "          target_path='nycflights',\n",
    "          show_progress=True)\n",
    "\n",
    "print(\"** Finished! **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Datastore on the Dask cluster\n",
    "\n",
    "Now, lets make use of the data on the Dask cluster you created in [StartDask.ipynb](StartDask.ipynb).\n",
    "You might have noticed that we launched the cluster with a --data parameter which instructed AzureML to mount the workspace's default Datastore onto all the workers of the cluster.\n",
    "\n",
    "```\n",
    "est = Estimator('dask', \n",
    "                compute_target=dask_cluster, \n",
    "                entry_script='startDask.py', \n",
    "                conda_dependencies_file_path='environment.yml', \n",
    "                script_params=\n",
    "                    {'--data': ws.get_default_datastore()},\n",
    "                node_count=10,\n",
    "                distributed_training=mpi_configuration)\n",
    "```\n",
    "\n",
    "At this time the local path on the compute is not determined, but it will be once the job starts. We therefore log the path back to the run history from which we can now retrieve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/batch/tasks/shared/LS_root/jobs/rapids/azureml/dask_1573618861_52e71160/mounts/workspaceblobstore/nycflights'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the last run on the dask experiment which should be running \n",
    "## our dask cluster, and retrieve the data path from it\n",
    "ws = Workspace.from_config()\n",
    "exp = ws.experiments['dask']\n",
    "cluster_run = exp.get_runs().__next__()\n",
    "\n",
    "if (not cluster_run.status == 'Running'):\n",
    "    raise Exception('Cluster should be in state \\'Running\\'')\n",
    "\n",
    "data_path = cluster_run.get_metrics()['data'] + '/nycflights'\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://localhost:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='http://localhost:8787/status' target='_blank'>http://localhost:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>39</li>\n",
       "  <li><b>Cores: </b>39</li>\n",
       "  <li><b>Memory: </b>284.09 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.0.0.14:8786' processes=39 threads=39, memory=284.09 GB>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the dask cluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "c = Client('tcp://localhost:8786')\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dask dataframe that loads the data from the path on the cluster\n",
    "import dask.dataframe as dd\n",
    "from dask import delayed\n",
    "\n",
    "def load_data(path):\n",
    "    df = dd.read_csv(path + '/*.csv',\n",
    "                 parse_dates={'Date': [0, 1, 2]},\n",
    "                 dtype={'TailNum': str,\n",
    "                        'CRSElapsedTime': float,\n",
    "                        'Cancelled': bool})    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to delay the excution of the read to make sure the path \n",
    "# evaluated on the cluster, not the client\n",
    "df = delayed(load_data)(data_path).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2611892\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>TailNum</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>...</th>\n",
       "      <th>AirTime</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>1540</td>\n",
       "      <td>1747.0</td>\n",
       "      <td>1701</td>\n",
       "      <td>US</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>EWR</td>\n",
       "      <td>PIT</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>1540</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1701</td>\n",
       "      <td>US</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>EWR</td>\n",
       "      <td>PIT</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-01-03</td>\n",
       "      <td>3</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>1540</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>1701</td>\n",
       "      <td>US</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>EWR</td>\n",
       "      <td>PIT</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-01-04</td>\n",
       "      <td>4</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>1540</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>1701</td>\n",
       "      <td>US</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>EWR</td>\n",
       "      <td>PIT</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-01-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>1540</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>1701</td>\n",
       "      <td>US</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>EWR</td>\n",
       "      <td>PIT</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  DayOfWeek  DepTime  CRSDepTime  ArrTime  CRSArrTime  \\\n",
       "0 1990-01-01          1   1621.0        1540   1747.0        1701   \n",
       "1 1990-01-02          2   1547.0        1540   1700.0        1701   \n",
       "2 1990-01-03          3   1546.0        1540   1710.0        1701   \n",
       "3 1990-01-04          4   1542.0        1540   1710.0        1701   \n",
       "4 1990-01-05          5   1549.0        1540   1706.0        1701   \n",
       "\n",
       "  UniqueCarrier  FlightNum TailNum  ActualElapsedTime  ...  AirTime  ArrDelay  \\\n",
       "0            US         33     NaN               86.0  ...      NaN      46.0   \n",
       "1            US         33     NaN               73.0  ...      NaN      -1.0   \n",
       "2            US         33     NaN               84.0  ...      NaN       9.0   \n",
       "3            US         33     NaN               88.0  ...      NaN       9.0   \n",
       "4            US         33     NaN               77.0  ...      NaN       5.0   \n",
       "\n",
       "   DepDelay  Origin Dest Distance  TaxiIn  TaxiOut  Cancelled  Diverted  \n",
       "0      41.0     EWR  PIT    319.0     NaN      NaN      False         0  \n",
       "1       7.0     EWR  PIT    319.0     NaN      NaN      False         0  \n",
       "2       6.0     EWR  PIT    319.0     NaN      NaN      False         0  \n",
       "3       2.0     EWR  PIT    319.0     NaN      NaN      False         0  \n",
       "4       9.0     EWR  PIT    319.0     NaN      NaN      False         0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now run some interactive queries\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    EWR\n",
       "1    LGA\n",
       "2    JFK\n",
       "Name: Origin, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Origin.unique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Origin\n",
       "EWR     876.278885\n",
       "JFK    1484.209596\n",
       "LGA     712.546238\n",
       "Name: Distance, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Origin').Distance.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Origin\n",
       "EWR    1139451\n",
       "JFK     427243\n",
       "LGA     974267\n",
       "Name: Origin, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df.Cancelled].groupby('Origin').Origin.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dest\n",
       "ORD    219060\n",
       "BOS    145105\n",
       "ATL    128855\n",
       "MIA    111001\n",
       "LAX    109848\n",
       "        ...  \n",
       "JFK         6\n",
       "CRP         2\n",
       "TUS         2\n",
       "ABQ         1\n",
       "STX         1\n",
       "Name: FlightNum, Length: 99, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest = df[~df.Cancelled].groupby('Dest').FlightNum.count().compute()\n",
    "dest.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
